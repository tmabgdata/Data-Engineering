# Data Engineering Repository

Welcome to the Data Engineering repository! This repository showcases a diverse collection of data engineering projects, highlighting my skills and expertise in designing, implementing, and optimizing data pipelines, storage solutions, and analysis workflows. Each project demonstrates the use of industry-standard tools and best practices to process, transform, and analyze data efficiently.

## Featured Projects

Below is an overview of the key projects in this repository:

### [Data Pipeline with Airflow, Azure Databricks, and Slack Integration](https://github.com/tmabgdata/Data-Engineering/tree/master/Airflow_Azure_Databricks_Pipeline)

This project implements a data pipeline to extract, transform, and report currency exchange rates using Airflow, Azure Databricks, and Slack. The pipeline performs the following key steps:

1. **Extraction**: Fetches daily currency exchange rates from a public API.
2. **Transformation**: Converts rates into different formats, performs aggregations, and additional calculations.
3. **Reporting**: Sends transformed data and generated graphs to a Slack channel.

### [Azure Data Lake Pipeline](https://github.com/tmabgdata/Data-Engineering/tree/master/Azure_Data_Lake_Pipeline)

This project highlights the creation of data pipelines using Azure Data Lake, focusing on efficient data ingestion, storage, and transformation. It includes real-world examples of managing large-scale data workflows on the Azure platform.

### [Azure Databricks and Data Factory](https://github.com/tmabgdata/Data-Engineering/tree/master/Azure_Databricks_DataFactory)

This project integrates Azure Databricks and Data Factory to create robust data processing pipelines. It demonstrates the orchestration of big data workflows and advanced analytics using these powerful Azure tools.


### [Data Engineer AWS Formation](https://github.com/tmabgdata/Data-Engineering/tree/master/Forma%C3%A7%C3%A3o%20Engenheiro%20de%20Dados%20AWS)

The "Formação Engenheiro de Dados AWS" project provides comprehensive insights into data engineering concepts and practices within the AWS ecosystem. This project includes hands-on exercises and real-world examples to solidify foundational skills.

### [Python, S3, and Redshift](https://github.com/tmabgdata/Data-Engineering/tree/master/Python_S3_Redshift)

This project demonstrates the integration of Python, Amazon S3, and Amazon Redshift for building ETL (Extract, Transform, Load) pipelines. It provides a practical guide to implementing scalable data workflows in the cloud.

### [Python, MongoDB](https://github.com/tmabgdata/Data-Engineering/tree/master/Python_%26_MongoDB)

A practice project showcasing the integration of Python with MongoDB to perform basic NoSQL database operations, including data queries, manipulations, and storage.

## How to Use

1. Navigate to individual project folders for detailed documentation, source code, and step-by-step guides.
2. Follow the instructions in each project's README to set up and execute the pipelines and workflows.
3. Explore the scripts and workflows to learn best practices and replicate similar solutions in your own environment.

## Contributions

Contributions are always welcome! If you'd like to enhance existing projects or add new data engineering analyses, feel free to:
- Open issues to suggest improvements or report bugs.
- Submit pull requests with your valuable contributions.

## Contact

For questions, feedback, or collaboration opportunities, reach out via my [GitHub profile](https://github.com/tmabgdata).

---

By Thiago Alves
